{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sparshnagpal/Desktop/projects/pdfquery/pdfquery_env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sparshnagpal/Desktop/projects/pdfquery/pdfquery_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import cassio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Python library which would assist reading the PDF file content\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_APPLICATION_TOKEN = *************\n",
    "ASTRA_DB_ID = **************\n",
    "\n",
    "OpenAI_API_Key = *****************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pdf file\n",
    "pdfreader = PdfReader('/Users/sparshnagpal/Desktop/projects/pdfquery/book.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect CassandraDB database (VectorDB)\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the LangChain embedding and LLM objects for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sparshnagpal/Desktop/projects/pdfquery/pdfquery_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/sparshnagpal/Desktop/projects/pdfquery/pdfquery_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=OpenAI_API_Key)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OpenAI_API_Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the table for embeddings in DB\n",
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1091, which is longer than the specified 800\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# We need to split the text using Character Text Splitter so that it should not increase the token size\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 50 headlines\n"
     ]
    }
   ],
   "source": [
    "astra_vector_store.add_texts(texts[:50])\n",
    "print(\"Inserted %i headlines\" %len(texts[:50]))\n",
    "\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: \"what is this book about?\"\n",
      "ANSWER: \"This book is about visual analysis tools and techniques, including a taxonomy of interactive dynamics and examples of systems that exhibit those dynamics. It also covers topics such as data and view specification, filtering, sorting, deriving values or models from data, and navigation and coordination of views for exploration.\"\n",
      "\n",
      "    [0.8659] \"Our focus on interactive elements presumes a basic familiarity with visualization de ...\"\n",
      "    [0.8659] \"Our focus on interactive elements presumes a basic familiarity with visualization de ...\"\n",
      "    [0.8651] \"The goal of this article is to assist designers, researchers, professional analysts, ...\"\n",
      "    [0.8650] \"E R U G I F \n",
      "  \n",
      "E R U G I F \n",
      "  \n",
      "E R U G I F \n",
      "  \n",
      "E R U G I F \n",
      "  E R U G I F \n",
      "  \n",
      "  \n",
      "   ...\"\n",
      "\n",
      "QUESTION: \"what does this book talk about?\"\n",
      "ANSWER: \"The book discusses a taxonomy of interactive dynamics for successful analytic dialogues in visual analysis tools. It also mentions the importance of familiarizing oneself with visualization design and recommends other resources for further reading.\"\n",
      "\n",
      "    [0.8798] \"Our focus on interactive elements presumes a basic familiarity with visualization de ...\"\n",
      "    [0.8798] \"Our focus on interactive elements presumes a basic familiarity with visualization de ...\"\n",
      "    [0.8769] \"The goal of this article is to assist designers, researchers, professional analysts, ...\"\n",
      "    [0.8769] \"The goal of this article is to assist designers, researchers, professional analysts, ...\"\n"
     ]
    }
   ],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input('\\nEnter your question (or type \"quit\" to exit): ').strip()\n",
    "    else:\n",
    "        query_text = input('\\nWhats your next  question (or type \"quit\" to exit): ').strip()\n",
    "    \n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfquery_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
